# -*- coding: utf-8 -*-
"""Customer Segmentation Final Year Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ot16HYx-QaNBZRFPheVunM7ikmid_yZi
"""

# Commented out IPython magic to ensure Python compatibility.
# Importing necessary packages

from google.colab import files  # Required to import dataset in google collab
# %matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import datetime as dt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

# Import dataset

or_dataset = pd.read_excel('https://github.com/Saurabhpatil-dev/dataset/raw/main/Online%20Retail.xlsx')
or_dataset.shape
or_dataset.head()

or_dataset.shape

or_dataset.info()

or_dataset.describe()

# Data Cleaning
df_null = round(100*(or_dataset.isnull().sum())/len(or_dataset), 2)
df_null

or_dataset = or_dataset.dropna()
or_dataset.shape

or_dataset=or_dataset[(or_dataset['Quantity']>0)]
or_dataset.describe()

or_dataset.shape

or_dataset['CustomerID'] = or_dataset['CustomerID'].astype(str)

# Data Preparation
or_dataset['Amount'] = or_dataset['Quantity']*or_dataset['UnitPrice']
rfm_m = or_dataset.groupby('CustomerID')['Amount'].sum()
rfm_m = rfm_m.reset_index()
rfm_m.head()

rfm_f = or_dataset.groupby('CustomerID')['InvoiceNo'].count()
rfm_f = rfm_f.reset_index()
rfm_f.columns = ['CustomerID', 'Frequency']
rfm_f.head()

# Merging the two dfs

rfm = pd.merge(rfm_m, rfm_f, on='CustomerID', how='inner')
rfm.head()

# New Attribute : Recency

# Convert to datetime to proper datatype

or_dataset['InvoiceDate'] = pd.to_datetime(or_dataset['InvoiceDate'],format='%d-%m-%Y %H:%M')

max_date = max(or_dataset['InvoiceDate'])
max_date

or_dataset['Diff'] = max_date - or_dataset['InvoiceDate']
or_dataset.head()

rfm_p = or_dataset.groupby('CustomerID')['Diff'].min()
rfm_p = rfm_p.reset_index()
rfm_p.head()

rfm_p['Diff'] = rfm_p['Diff'].dt.days
rfm_p.head()

rfm = pd.merge(rfm, rfm_p, on='CustomerID', how='inner')
rfm.columns = ['CustomerID', 'Amount', 'Frequency', 'Recency']
rfm.head()

def RScoring(x,p,d):
    if x <= d[p][0.25]:
        return 1
    elif x <= d[p][0.50]:
        return 2
    elif x <= d[p][0.75]: 
        return 3
    else:
        return 4
    
def FandMScoring(x,p,d):
    if x <= d[p][0.25]:
        return 4
    elif x <= d[p][0.50]:
        return 3
    elif x <= d[p][0.75]: 
        return 2
    else:
        return 1

# Split data using Quantiles to sub divide it into four parts
qt = rfm.quantile(q=[0.25,0.5,0.75])
qt = qt.to_dict()

print(qt)

rfm['R'] = rfm['Recency'].apply(RScoring, args=('Recency',qt,))
rfm['F'] = rfm['Frequency'].apply(FandMScoring, args=('Frequency',qt,))
rfm['M'] = rfm['Amount'].apply(FandMScoring, args=('Amount',qt,))
rfm.head()

rfm['Group'] = rfm.R.map(str) + rfm.F.map(str) + rfm.M.map(str)
rfm['Score'] = rfm[['R', 'F', 'M']].sum(axis = 1)
rfm.head()

#Assign Tier to each customer
Tier = ['Tier 1', 'Tier 2', 'Tier 3', 'Tier 4']
Score_cuts = pd.qcut(rfm.Score, q = 4, labels = Tier)
rfm['Tier'] = Score_cuts.values
rfm.reset_index().head()

rfm['Tier'].value_counts()

print(rfm.Recency.describe())
print()
print(rfm.Frequency.describe())
print()
print(rfm.Amount.describe())

# Outlier Analysis of Amount Frequency and Recency

attributes = ['Amount','Frequency','Recency']
plt.rcParams['figure.figsize'] = [10,8]
sns.boxplot(data = rfm[attributes], orient="v", palette="Set2" ,whis=1.5,saturation=1, width=0.7)
plt.title("Outliers Variable Distribution", fontsize = 14, fontweight = 'bold')
plt.ylabel("Range", fontweight = 'bold')
plt.xlabel("Attributes", fontweight = 'bold')

# Removing (statistical) outliers for Amount
Q1 = rfm.Amount.quantile(0.25)
Q3 = rfm.Amount.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.Amount >= Q1 - 1.5*IQR) & (rfm.Amount <= Q3 + 1.5*IQR)]

# Removing (statistical) outliers for Recency
Q1 = rfm.Recency.quantile(0.25)
Q3 = rfm.Recency.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.Recency >= Q1 - 1.5*IQR) & (rfm.Recency <= Q3 + 1.5*IQR)]

# Removing (statistical) outliers for Frequency
Q1 = rfm.Frequency.quantile(0.25)
Q3 = rfm.Frequency.quantile(0.75)
IQR = Q3 - Q1
rfm = rfm[(rfm.Frequency >= Q1 - 1.5*IQR) & (rfm.Frequency <= Q3 + 1.5*IQR)]

# Rescaling the attributes

rfm_df = rfm[['Amount', 'Frequency', 'Recency']]

# Instantiate
scaler = StandardScaler()

# fit_transform
rfm_df_scaled = scaler.fit_transform(rfm_df)
rfm_df_scaled.shape

rfm_df_scaled = pd.DataFrame(rfm_df_scaled)
rfm_df_scaled.columns = ['Amount', 'Frequency', 'Recency']
rfm_df_scaled.head()

kmeans = KMeans(n_clusters=4, max_iter=50)
kmeans.fit(rfm_df_scaled)

kmeans.labels_

ssqd = {}
for k in range(1,10):
    km = KMeans(n_clusters= k, max_iter=50)
    km = km.fit(rfm_df_scaled)
    # ssqd.append(km.inertia_)
    ssqd[k] = km.inertia_
    plt.style.use('ggplot')
    # Plot graph for optimal number of clusters
    plt.figure(figsize=(7, 5))
    sns.pointplot(x = list(ssqd.keys()), y = list(ssqd.values()))
    plt.xlabel('Number of Clusters').set_size(20)
    plt.ylabel('Sum of Square Distances').set_size(20)
    plt.title('Elbow Method').set_size(25)
    plt.show()
# plt.plot(ssqd)

from sklearn.metrics import silhouette_samples, silhouette_score
# Silhouette analysis
range_n_clusters = [2, 3, 4, 5, 6, 7, 8]

for num_clusters in range_n_clusters:
    
    # intialise kmeans
    kmeans = KMeans(n_clusters=num_clusters, max_iter=50)
    kmeans.fit(rfm_df_scaled)
    
    cluster_labels = kmeans.labels_
    
    # silhouette score
    silhouette_avg = silhouette_score(rfm_df_scaled, cluster_labels).round(4)
    print("For No_Cl={0}, the silhouette score is {1}".format(num_clusters, silhouette_avg))

# Final model with k=3
kmeans = KMeans(n_clusters=3, max_iter=50)
kmeans.fit(rfm_df_scaled)

kmeans.labels_

rfm.drop('Tier', axis='columns', inplace=True)

# assign the label
rfm['Tier'] = kmeans.labels_
rfm.head()

plt.figure(figsize=(7, 5))
sns.boxplot(x='Tier', y='Amount', data=rfm)
plt.xlabel('Tier Level').set_size(15)
plt.ylabel('Monetary').set_size(15)
plt.title('Tier level based on Monetary').set_size(20)
plt.show()

plt.figure(figsize=(7, 5))
sns.boxplot(x='Tier', y='Frequency', data=rfm)
plt.xlabel('Tier Level').set_size(15)
plt.ylabel('Frequency').set_size(15)
plt.title('Tier level based on Frequency').set_size(20)
plt.show()

plt.figure(figsize=(7, 5))
sns.boxplot(x='Tier', y='Recency', data=rfm)
plt.xlabel('Tier Level').set_size(15)
plt.ylabel('Recency').set_size(15)
plt.title('Tier level based on Recency').set_size(20)
plt.show()

"""#Conclusion


---
1. Customer in Tier 0 are least active customers.
2. Customer in Tier 1 have higher frequency rate and high spending.
3. Customer in Tier 2 have good recency in comparision to other customers.
   





"""